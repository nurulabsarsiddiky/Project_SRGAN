{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c7cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06625a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8a7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchmetrics import Accuracy, F1Score, AUROC, Precision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import VGG16_Weights, ResNet18_Weights\n",
    "from torch.nn import functional as F\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torchvision.models\n",
    "from PIL import Image\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3c8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformation(size=128):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size=(size, size)),\n",
    "        transforms.RandomRotation(degrees=(-45, 45)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomApply(torch.nn.ModuleList([transforms.GaussianBlur(kernel_size=3)]), p=0.5),\n",
    "        transforms.RandomApply(\n",
    "            torch.nn.ModuleList([transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.2, hue=0.2)]),\n",
    "            p=0.5),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f481c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_transformation(size=224):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size=(size, size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c562ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalImage(Dataset):\n",
    "    def __init__(self, data_root, transformation, mode=\"train\"):\n",
    "        self.data_root = data_root\n",
    "        self.transformation = transformation\n",
    "        self.list_imgs = os.listdir(self.data_root)\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.list_imgs[idx]\n",
    "        img = self.load_img(img_path=self.data_root + \"/\" + img_name)\n",
    "        img = self.transformation(img)\n",
    "        label = 0  # if it's a dog then label = 0\n",
    "        if \"cat\" in img_name:\n",
    "            label = 1\n",
    "\n",
    "        return {\"img\": img, \"label\": label}\n",
    "\n",
    "    def load_img(self, img_path):\n",
    "        img = Image.open(img_path)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5f7128",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, model, lr, wd):\n",
    "        super().__init__()\n",
    "        # Define metrics for binary classification\n",
    "        self.initialize_metrics()\n",
    "        self.model = model\n",
    "        self.model.fc = torch.nn.Sequential(\n",
    "            model.fc,\n",
    "            torch.nn.Linear(1000, 1),\n",
    "        )\n",
    "\n",
    "        self.lr = lr\n",
    "        self.wd = wd\n",
    "\n",
    "    def initialize_metrics(self):\n",
    "        task = \"binary\"\n",
    "        self.metrics_list = [\"accuracy\", \"precision\", \"f1\", \"auc\"]\n",
    "        self.sessions = [\"train\", \"val\", \"test\"]\n",
    "        self.classes = [(\"cat\", 1), (\"dog\", 0)]\n",
    "\n",
    "        self.train_ac = Accuracy(task=task, average=\"macro\")\n",
    "        self.val_ac = Accuracy(task=task, average=\"macro\")\n",
    "        self.test_ac = Accuracy(task=task, average=\"macro\")\n",
    "\n",
    "        self.train_p = Precision(task=task, average=\"macro\")\n",
    "        self.val_p = Precision(task=task, average=\"macro\")\n",
    "        self.test_p = Precision(task=task, average=\"macro\")\n",
    "\n",
    "        self.train_f1 = F1Score(task=task, average=\"macro\")\n",
    "        self.val_f1 = F1Score(task=task, average=\"macro\")\n",
    "        self.test_f1 = F1Score(task=task, average=\"macro\")\n",
    "\n",
    "        self.train_auc = AUROC(task=task, average=\"macro\")\n",
    "        self.val_auc = AUROC(task=task, average=\"macro\")\n",
    "        self.test_auc = AUROC(task=task, average=\"macro\")\n",
    "\n",
    "        self.metrics = {\"train\": [self.train_ac, self.train_p, self.train_f1, self.train_auc],\n",
    "                        \"val\": [self.val_ac, self.val_p, self.val_f1, self.val_auc],\n",
    "                        \"test\": [self.test_ac, self.test_p, self.test_f1, self.test_auc],\n",
    "                        }\n",
    "        self.step_output = {\"train\": [], \"val\": [], \"test\": []}\n",
    "        self.mean_log_keys = [\"loss\"]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    # Calculate the loss for the given batch\n",
    "    def _calculate_loss(self, batch):\n",
    "        imgs, labels = batch[\"img\"], batch[\"label\"].float().unsqueeze(1)\n",
    "        preds = self.forward(imgs)\n",
    "        loss = F.binary_cross_entropy_with_logits(preds, labels)\n",
    "        return {\"loss\": loss, \"preds\": preds, \"labels\": labels}\n",
    "\n",
    "    # For model A\n",
    "          # Training step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        output = self._calculate_loss(batch)\n",
    "        self.step_output[\"train\"].append(output)\n",
    "        return output[\"loss\"]\n",
    "    def on_train_epoch_end(self):\n",
    "        self.stack_update(session=\"train\")\n",
    "\n",
    "    # Validation:\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        output = self._calculate_loss(batch)\n",
    "        self.step_output[\"val\"].append(output)\n",
    "        return output[\"loss\"]\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.stack_update(session=\"val\")\n",
    "\n",
    "    # Test:\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        output = self._calculate_loss(batch)\n",
    "        self.step_output[\"test\"].append(output)\n",
    "        return output[\"loss\"]\n",
    "\n",
    "    # Actions to perform at the end of each test epoch\n",
    "    def on_test_epoch_end(self, ):\n",
    "        self.stack_update(session=\"test\")\n",
    "\n",
    "    # Update metrics with predictions and labels\n",
    "    def update_metrics(self, session, preds, labels):\n",
    "        for metric in self.metrics[session]:\n",
    "            metric.update(preds, labels)\n",
    "            \n",
    "    # Preparation for Model B: SRGAN model\n",
    "    def stack_update(self, session):\n",
    "        all_preds = torch.cat([out[\"preds\"] for out in self.step_output[session]])\n",
    "        all_labels = torch.cat([out[\"labels\"] for out in self.step_output[session]])\n",
    "        log = {}\n",
    "        for key in self.mean_log_keys:\n",
    "            log[f\"{session}_{key}\"] = torch.stack([out[key] for out in self.step_output[session]]).mean()\n",
    "\n",
    "        self.update_metrics(session=session, preds=all_preds, labels=all_labels)\n",
    "        res = self.compute_metrics(session=session)\n",
    "        self.add_log(session, res, log)\n",
    "        self.log_dict(log, sync_dist=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.restart_metrics(session=session)\n",
    "\n",
    "        return all_preds, all_labels\n",
    "\n",
    "    def compute_metrics(self, session):\n",
    "        res = {}\n",
    "        for metric, metric_name in zip(self.metrics[session], self.metrics_list):\n",
    "            res[metric_name] = metric.compute()\n",
    "        return res\n",
    "\n",
    "    def restart_metrics(self, session):\n",
    "        for metric in self.metrics[session]:\n",
    "            metric.reset()\n",
    "        self.step_output[session].clear()  # free memory\n",
    "\n",
    "    # Metrics to the SRGAN_train.log\n",
    "    \n",
    "    def add_log(self, session, res, log):\n",
    "        for metric in self.metrics_list:\n",
    "            log[session + f\"_{metric}\"] = res[metric]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "badceabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=10):\n",
    "    pl.seed_everything(seed)\n",
    "    np.random.seed(seed=seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.set_float32_matmul_precision('medium')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "215b8fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 10\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: checkpoints/Model_A/tb_log/resnet18\n",
      "/home/mdnurualabsarsiddiky/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/mdnurualabsarsiddiky/.local/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /home/mdnurualabsarsiddiky/Desktop/Absar/MidTerm_ECGR8119/Model_A/checkpoints/Model_A exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name      | Type            | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0  | train_ac  | BinaryAccuracy  | 0      | train\n",
      "1  | val_ac    | BinaryAccuracy  | 0      | train\n",
      "2  | test_ac   | BinaryAccuracy  | 0      | train\n",
      "3  | train_p   | BinaryPrecision | 0      | train\n",
      "4  | val_p     | BinaryPrecision | 0      | train\n",
      "5  | test_p    | BinaryPrecision | 0      | train\n",
      "6  | train_f1  | BinaryF1Score   | 0      | train\n",
      "7  | val_f1    | BinaryF1Score   | 0      | train\n",
      "8  | test_f1   | BinaryF1Score   | 0      | train\n",
      "9  | train_auc | BinaryAUROC     | 0      | train\n",
      "10 | val_auc   | BinaryAUROC     | 0      | train\n",
      "11 | test_auc  | BinaryAUROC     | 0      | train\n",
      "12 | model     | ResNet          | 11.7 M | train\n",
      "-------------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.762    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dab1e7a457d4e229c2a5b25b2196881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load the resnet model with pre-trained weights\n",
    "    model_architecture = torchvision.models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model = Model(model=model_architecture, lr=1e-4, wd=1e-6)\n",
    "\n",
    "    max_epochs = 100\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "    model_path = \"checkpoints/Model_A\"\n",
    "    batch_size = 32\n",
    "    # Set seed for reproducibility\n",
    "    seed = 10\n",
    "    set_seed(seed)\n",
    "    # Create dataset and split it into train, and validation\n",
    "    cat_dog_dataset = AnimalImage(data_root=\"/home/mdnurualabsarsiddiky/Desktop/Absar/ECGR8119/Midterm_2024/dogs_vs_cats/train\", transformation=get_transformation())\n",
    "    train_data, val_data, _ = random_split(cat_dog_dataset, [0.6, 0.1, 0.3],\n",
    "                                           generator=torch.Generator().manual_seed(seed))\n",
    "    ##\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=2, drop_last=False)\n",
    "\n",
    "    # Set up logging for training progress\n",
    "    csv_logger = pl_loggers.CSVLogger(save_dir=os.path.join(model_path, \"SRGAN/SRGAN_train.log/\"))\n",
    "    tb_logger = TensorBoardLogger(save_dir=os.path.join(model_path, \"tb_log/\"), name=\"resnet18\")\n",
    "    # Define early stopping criteria\n",
    "    monitor = \"val_loss\"\n",
    "    mode = \"min\"\n",
    "    early_stopping = EarlyStopping(monitor=monitor, patience=10, verbose=False, mode=mode)\n",
    "    # Initialize the trainer and start training\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=model_path,\n",
    "        accelerator=\"gpu\",\n",
    "        max_epochs=max_epochs,\n",
    "        callbacks=[\n",
    "            early_stopping,\n",
    "            ModelCheckpoint(dirpath=model_path, filename=\"resnet18-{epoch}-{val_loss:.2f}\", save_top_k=1,\n",
    "                            save_weights_only=True, mode=mode, monitor=monitor),\n",
    "        ],\n",
    "        logger=[tb_logger, csv_logger],\n",
    "    )\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f8878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
